{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ed85e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3b736db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as FT\n",
    "\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 이미지 불러오기 및 그리기\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "8349eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipynb 파일 import 하기.\n",
    "import import_ipynb\n",
    "\n",
    "# utils.ipynb에 있는 함수 가지고 오기.\n",
    "from utils import (\n",
    "    non_max_suppression,\n",
    "    mean_average_precision,\n",
    "    intersection_over_union,\n",
    "    cellboxes_to_boxes,\n",
    "    get_bboxes,\n",
    "    plot_image,\n",
    "    save_checkpoint,\n",
    "    load_checkpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c834e447",
   "metadata": {},
   "source": [
    "## 변수 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "67994407",
   "metadata": {},
   "outputs": [],
   "source": [
    "ori_dir = './'\n",
    "img_dir = ori_dir + 'image/'\n",
    "label_dir = ori_dir + 'label_txt/'\n",
    "\n",
    "train_csv = ori_dir + 'png_txt.csv'\n",
    "\n",
    "img_size = 416\n",
    "S = 7   # grid cell w,h크기\n",
    "C = 4\n",
    "\n",
    "classes = [ \"AC\", \"FL\", \"HC\", \"HUM\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5e2a0547",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "에러 내용 : TypeError: __call__() takes 2 positional arguments but 3 were given. self.\n",
    "https://stackoverflow.com/questions/62341052/typeerror-call-takes-2-positional-arguments-but-3-were-given-to-train-ra\n",
    "\n",
    "해결\n",
    "아래 있는 Compose 함수를 호출해서 transform을 하니 해결이 됨.\n",
    "'''\n",
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img, bboxes):\n",
    "        for t in self.transforms:\n",
    "            img, bboxes = t(img), bboxes\n",
    "\n",
    "        return img, bboxes\n",
    "\n",
    "transform = Compose([transforms.Resize((448, 448)), transforms.ToTensor(),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "35ea393b",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 123\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# Hyperparameters etc. \n",
    "LEARNING_RATE = 2e-5\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available else \"cpu\"\n",
    "BATCH_SIZE = 16 # 64 in original paper but I don't have that much vram, grad accum?\n",
    "WEIGHT_DECAY = 0\n",
    "EPOCHS = 3\n",
    "NUM_WORKERS = 2\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = False\n",
    "LOAD_MODEL_FILE = \"overfit.pth.tar\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c47a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d06ed37",
   "metadata": {},
   "source": [
    "# bbox 좌표 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3ac2f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "df = pd.read_csv(train_csv)\n",
    "\n",
    "info_csv = ori_dir + 'result_center.csv'\n",
    "info = pd.read_csv(info_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "805edda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_png</th>\n",
       "      <th>img_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20151103_E0000056_I0004613.png</td>\n",
       "      <td>20151103_E0000056_I0004613.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20151103_E0000057_I0004695.png</td>\n",
       "      <td>20151103_E0000057_I0004695.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20151103_E0000057_I0004696.png</td>\n",
       "      <td>20151103_E0000057_I0004696.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20151103_E0000058_I0004790.png</td>\n",
       "      <td>20151103_E0000058_I0004790.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20151103_E0000059_I0004888.png</td>\n",
       "      <td>20151103_E0000059_I0004888.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          img_png                         img_txt\n",
       "0  20151103_E0000056_I0004613.png  20151103_E0000056_I0004613.txt\n",
       "1  20151103_E0000057_I0004695.png  20151103_E0000057_I0004695.txt\n",
       "2  20151103_E0000057_I0004696.png  20151103_E0000057_I0004696.txt\n",
       "3  20151103_E0000058_I0004790.png  20151103_E0000058_I0004790.txt\n",
       "4  20151103_E0000059_I0004888.png  20151103_E0000059_I0004888.txt"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e0865a84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_name</th>\n",
       "      <th>class</th>\n",
       "      <th>center_x</th>\n",
       "      <th>center_y</th>\n",
       "      <th>w</th>\n",
       "      <th>h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20151103_E0000056_I0004613.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4629</td>\n",
       "      <td>0.4824</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>0.5312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20151103_E0000057_I0004695.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5620</td>\n",
       "      <td>0.4150</td>\n",
       "      <td>0.2393</td>\n",
       "      <td>0.4785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20151103_E0000057_I0004696.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5474</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>0.2275</td>\n",
       "      <td>0.4785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20151103_E0000058_I0004790.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4785</td>\n",
       "      <td>0.6377</td>\n",
       "      <td>0.1719</td>\n",
       "      <td>0.3574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20151103_E0000059_I0004888.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4883</td>\n",
       "      <td>0.5078</td>\n",
       "      <td>0.1934</td>\n",
       "      <td>0.3867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         img_name  class  center_x  center_y       w       h\n",
       "0  20151103_E0000056_I0004613.png      0    0.4629    0.4824  0.2559  0.5312\n",
       "1  20151103_E0000057_I0004695.png      0    0.5620    0.4150  0.2393  0.4785\n",
       "2  20151103_E0000057_I0004696.png      0    0.5474    0.3975  0.2275  0.4785\n",
       "3  20151103_E0000058_I0004790.png      0    0.4785    0.6377  0.1719  0.3574\n",
       "4  20151103_E0000059_I0004888.png      0    0.4883    0.5078  0.1934  0.3867"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1325680f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03d1a6bf",
   "metadata": {},
   "source": [
    "# bbox가 이미지에서 잘 위치한지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4ac5141",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bbox(img_file, boxes):\n",
    "    # 이미지를 로드합니다.\n",
    "    image = cv2.imread(img_file)\n",
    "    \n",
    "    # 바운딩 박스 좌표를 추출합니다.\n",
    "    c, x, y, w, h = boxes\n",
    "    x1, y1 = int((x - w/2) * 1024) , int((y - h/2) * 512)\n",
    "    x2, y2 = int((x + w/2) * 1024) , int((y + h/2) * 512)\n",
    "\n",
    "    # 바운딩 박스를 시각화합니다.\n",
    "    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    # center 좌표 보기.\n",
    "    #cv2.line(image, (x, y), (x, y), (0, 0, 255), 3)\n",
    "    # 해당 이미지 class 확인\n",
    "    cv2.putText(image, str(c), (x2, y1), cv2.FONT_HERSHEY_SIMPLEX, 1, (0,255,0), 2)\n",
    "    \n",
    "    \n",
    "    # 시각화된 이미지를 보여줍니다.\n",
    "    cv2.imshow('Bounding Boxes', image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dfc028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_file = img_dir + df['img_png'][0]\n",
    "boxes = info['class'][0] , info['center_x'][0] , info['center_y'][0] , info['w'][0] , info['h'][0]\n",
    "\n",
    "draw_bbox(img_file , boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cb6417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29d56756",
   "metadata": {},
   "source": [
    "# Dataset 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "15b8ae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VOCDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self, csv_file, img_dir, label_dir, S=7, B=2, C=4, transform=None,\n",
    "    ):\n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.transform = transform\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # 이미지 객체 정보 가져오기.\n",
    "        label_path = os.path.join(self.label_dir, self.annotations.iloc[index, 1])\n",
    "        boxes = []\n",
    "        \n",
    "        with open(label_path) as f:\n",
    "            for label in f.readlines():\n",
    "                # 이 순서대로 txt파일에 저장되어있음.\n",
    "                class_label, x, y, width, height = [\n",
    "                    float(x) if float(x) != int(float(x)) else int(x)\n",
    "                    for x in label.replace(\"\\n\", \"\").split()\n",
    "                ]\n",
    "                \n",
    "                # boxes 변수에 이미지 정보 한번에 배열로 저장하기.\n",
    "                boxes.append([class_label, x, y, width, height])\n",
    "                \n",
    "                \n",
    "        # 이미지 파일 불러오기.\n",
    "        img_path = os.path.join(self.img_dir, self.annotations.iloc[index, 0])\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        # 이미지 정보를 tensor로 변환해주기.\n",
    "        boxes = torch.tensor(boxes)\n",
    "\n",
    "        if self.transform:\n",
    "            '''\n",
    "            image = self.transform(image)\n",
    "            boxes = self.transform(boxes)\n",
    "            '''\n",
    "            image, boxes = self.transform(image, boxes)\n",
    "\n",
    "        # ====================================================== \n",
    "        # ENCODING\n",
    "        # 이미지를 SxS그리드로 나누고, feature map의 tensor는 S x S x (B*5 + C). 5 : x, y, w, h, confidence\n",
    "        label_matrix = torch.zeros((self.S, self.S, self.C + 5 * self.B))\n",
    "        for box in boxes:\n",
    "            class_label, x, y, width, height = box.tolist()\n",
    "            class_label = int(class_label)\n",
    "\n",
    "            # 객체가 속한 grid cell의 행(=i)과 열(=j)을 계산한다.\n",
    "            i, j = int(self.S * y), int(self.S * x)\n",
    "            # cell 내에서 객체의 상대적인 좌표 계산.\n",
    "            x_cell, y_cell = self.S * x - j, self.S * y - i\n",
    "            \n",
    "            \"\"\"\n",
    "            cell 기준으로 bbox cell의 너비와 높이 계산.\n",
    "            \n",
    "            width_pixels = (width*self.image_width)\n",
    "            cell_pixels = (self.image_width)\n",
    "            \n",
    "            cell의 상대적인 너비를 찾는 방법 : width_pixels/cell_pixels\n",
    "            \"\"\"\n",
    "            width_cell, height_cell = (\n",
    "                width * self.S,\n",
    "                height * self.S,\n",
    "            )\n",
    "\n",
    "            # label_matrix가 현재 모든 값이 0인 상태이다.\n",
    "            # 이때 위에서 구한 grid cell에서의 객체 좌표에 대한 정보를 넣을 것이다.\n",
    "            # 좌표가 i, j일 때 해당 값이 0이라면 1값을 넣어준다.\n",
    "            # 13 : 객체가 존재하는지를 나타내는 index\n",
    "            if label_matrix[i, j, 4] == 0:\n",
    "                # 객체가 있다면 1을 넣어준다.\n",
    "                label_matrix[i, j, 4] = 1\n",
    "\n",
    "                # box 좌표\n",
    "                # cell 내에서의 bbox 좌표 및 너비를 텐서로 전환 후 저장.\n",
    "                box_coordinates = torch.tensor([\n",
    "                    x_cell, y_cell,\n",
    "                    min(width_cell, self.S - 1),\n",
    "                    min(height_cell, self.S - 1)\n",
    "                ])\n",
    "                # 14 ~ 23번째 index에 값 저장.\n",
    "                label_matrix[i, j, 5:9] = box_coordinates\n",
    "\n",
    "                # class_label에 대해 one-hot encoding 해주기.\n",
    "                # 값이 있는 cell을 1로 저장.\n",
    "                label_matrix[i, j, class_label] = 1\n",
    "                \n",
    "        return image, label_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f3fdaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5635436",
   "metadata": {},
   "source": [
    "# yolov1 network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "a8c3b4b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Information about architecture config:\n",
    "Tuple is structured : (kernel_size, filters, stride, padding) \n",
    "\"M\" is simply maxpooling with stride 2x2 and kernel 2x2\n",
    "List is structured by tuples and lastly int with number of repeats\n",
    "\"\"\"\n",
    "\n",
    "architecture_config = [\n",
    "    (7, 64, 2, 3),\n",
    "    \"M\",\n",
    "    \n",
    "    (3, 192, 1, 1),\n",
    "    \"M\",\n",
    "    \n",
    "    (1, 128, 1, 0),\n",
    "    (3, 256, 1, 1),\n",
    "    (1, 256, 1, 0),\n",
    "    (3, 512, 1, 1),\n",
    "    \"M\",\n",
    "    \n",
    "    [(1, 256, 1, 0), (3, 512, 1, 1), 4],   # -> conv 4번 반복\n",
    "    (1, 512, 1, 0),\n",
    "    (3, 1024, 1, 1),\n",
    "    \"M\",\n",
    "    \n",
    "    [(1, 512, 1, 0), (3, 1024, 1, 1), 2],  # -> conv 2번 반복\n",
    "    (3, 1024, 1, 1),\n",
    "    (3, 1024, 2, 1),\n",
    "    \n",
    "    (3, 1024, 1, 1),\n",
    "    (3, 1024, 1, 1),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f81242",
   "metadata": {},
   "source": [
    "### CNN block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "1166005f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, **kwargs):\n",
    "        super(CNNBlock, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, bias=False, **kwargs)\n",
    "        self.batchnorm = nn.BatchNorm2d(out_channels)\n",
    "        self.leakyrelu = nn.LeakyReLU(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.leakyrelu(self.batchnorm(self.conv(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c07e998d",
   "metadata": {},
   "source": [
    "# Yolov1 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "227f6229",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yolov1(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels=3, **kwargs):\n",
    "        super(Yolov1, self).__init__()\n",
    "        self.architecture = architecture_config\n",
    "        self.in_channels = in_channels\n",
    "        self.darknet = self._create_conv_layers(self.architecture)\n",
    "        self.fcs = self._create_fcs(**kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.darknet(x)\n",
    "        return self.fcs(torch.flatten(x, start_dim=1))\n",
    "\n",
    "    def _create_conv_layers(self, architecture):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "\n",
    "        for x in architecture:\n",
    "            # arch_config에서 값이 tuple인 경우 : (7, 64, 2, 3)\n",
    "            if type(x) == tuple:\n",
    "                layers += [\n",
    "                    CNNBlock(\n",
    "                        in_channels, x[1], kernel_size=x[0], stride=x[2], padding=x[3],\n",
    "                    )\n",
    "                ]\n",
    "                in_channels = x[1]\n",
    "                \n",
    "            # arch_config에서 값이 string인 경우 : 'M'\n",
    "            # -> maxpooling\n",
    "            elif type(x) == str:\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
    "                \n",
    "            # arch_config에서 값이 list인 경우 : [(1, 256, 1, 0), (3, 512, 1, 1), 4]\n",
    "            elif type(x) == list:\n",
    "                conv1 = x[0]\n",
    "                conv2 = x[1]\n",
    "                num_repeats = x[2]\n",
    "                \n",
    "                # 2번 혹은 4번 돌아감.\n",
    "                for _ in range(num_repeats):\n",
    "                    \n",
    "                    # 1x1 conv인 경우\n",
    "                    layers += [\n",
    "                        CNNBlock(\n",
    "                            in_channels,\n",
    "                            conv1[1],\n",
    "                            kernel_size=conv1[0],\n",
    "                            stride=conv1[2],\n",
    "                            padding=conv1[3],\n",
    "                        )\n",
    "                    ]\n",
    "                    \n",
    "                    # 3x3 conv인 경우\n",
    "                    layers += [\n",
    "                        CNNBlock(\n",
    "                            conv1[1],\n",
    "                            conv2[1],\n",
    "                            kernel_size=conv2[0],\n",
    "                            stride=conv2[2],\n",
    "                            padding=conv2[3],\n",
    "                        )\n",
    "                    ]\n",
    "                    in_channels = conv2[1]\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def _create_fcs(self, split_size, num_boxes, num_classes):\n",
    "        S, B, C = split_size, num_boxes, num_classes\n",
    "\n",
    "        # In original paper this should be\n",
    "        # nn.Linear(1024*S*S, 4096),\n",
    "        # nn.LeakyReLU(0.1),\n",
    "        # nn.Linear(4096, S*S*(B*5+C))\n",
    "\n",
    "        return nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(1024 * S * S, 496),\n",
    "            nn.Dropout(0.0),\n",
    "            nn.LeakyReLU(0.1),\n",
    "            nn.Linear(496, S * S * (C + B * 5)),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "38268c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Yolov1(split_size=7, num_boxes=2, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3817863d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yolov1(\n",
       "  (darknet): Sequential(\n",
       "    (0): CNNBlock(\n",
       "      (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (batchnorm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (1): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (2): CNNBlock(\n",
       "      (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (3): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (4): CNNBlock(\n",
       "      (conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (5): CNNBlock(\n",
       "      (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (6): CNNBlock(\n",
       "      (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (7): CNNBlock(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (8): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): CNNBlock(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (10): CNNBlock(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (11): CNNBlock(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (12): CNNBlock(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (13): CNNBlock(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (14): CNNBlock(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (15): CNNBlock(\n",
       "      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (16): CNNBlock(\n",
       "      (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (17): CNNBlock(\n",
       "      (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (18): CNNBlock(\n",
       "      (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (19): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), padding=0, dilation=1, ceil_mode=False)\n",
       "    (20): CNNBlock(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (21): CNNBlock(\n",
       "      (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (22): CNNBlock(\n",
       "      (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (23): CNNBlock(\n",
       "      (conv): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (24): CNNBlock(\n",
       "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (25): CNNBlock(\n",
       "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (26): CNNBlock(\n",
       "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "    (27): CNNBlock(\n",
       "      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (batchnorm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (leakyrelu): LeakyReLU(negative_slope=0.1)\n",
       "    )\n",
       "  )\n",
       "  (fcs): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=50176, out_features=496, bias=True)\n",
       "    (2): Dropout(p=0.0, inplace=False)\n",
       "    (3): LeakyReLU(negative_slope=0.1)\n",
       "    (4): Linear(in_features=496, out_features=686, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "877e2084",
   "metadata": {},
   "source": [
    "# LOSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "de6bdd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class YoloLoss(nn.Module):\n",
    "    \n",
    "    def __init__(self, S=7, B=2, C=4):\n",
    "        super(YoloLoss, self).__init__()\n",
    "        self.mse = nn.MSELoss(reduction=\"sum\")\n",
    "\n",
    "        \"\"\"\n",
    "        S is split size of image (in paper 7),\n",
    "        B is number of boxes (in paper 2),\n",
    "        C is number of classes (in paper and VOC dataset is 4),\n",
    "        \"\"\"\n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "\n",
    "        # These are from Yolo paper, signifying how much we should\n",
    "        # pay loss for no object (noobj) and the box coordinates (coord)\n",
    "        self.lambda_noobj = 0.5\n",
    "        self.lambda_coord = 5   # 상자 좌표\n",
    "        \n",
    "    # 손실함수 계산 시작\n",
    "    def forward(self, predictions, target):\n",
    "        # predictions : 모델의 출력으로 받은 예측 값.\n",
    "        # target : 실제 target 값. 모델이 예측하려는 bbox와 클래스 정보 포함.\n",
    "        \n",
    "        # grid cell 형태로 예측값들을 다시 배치하기 위해서 pred를 재구조화한다.\n",
    "        '''\n",
    "        predictions 입력 시 shape : (BATCH_SIZE, S, S, (C+B*5))\n",
    "        \n",
    "        [..., :C] = 각 클래스에 대한 확률  /  [..., C:C+4] : 첫 번째 bbox에 대한 좌표 및 너비(x, y, w, h)\n",
    "        [..., C+4:C+5] : 첫 번째 bbox에 대한 confidence score\n",
    "        \n",
    "        [..., C+6:C+9] : 두 번째 bbox에 대한 좌표 및 너비(x, y, w, h)\n",
    "        [..., C+9:C+10] : 두 번째 bbox에 대한 confidence score\n",
    "        \n",
    "        target 입력 시 shape : (BATCH_SIZE, S, S, (C+B*5))\n",
    "        [..., :4] : 각 target bbox 실제 좌표 및 너비(x, y, w, h)\n",
    "        [..., 4:5] : 각 target bbox에 대한 존재 여부 (1=객체있음 , 0=객체없음)\n",
    "        [..., 5:C+5] : 각 target bbox에 대한 class 정보로 one-hot encoding된 벡터.\n",
    "                       ex) 만약 class=2 -> [0, 1, 0, 0]으로 표현\n",
    "        '''\n",
    "        \n",
    "        predictions = predictions.reshape(-1, self.S, self.S, self.C + self.B * 5)\n",
    "        print('predictions', predictions)\n",
    "        \n",
    "        # intersection_over_union -> utils.ipybn 파일에 있는 함수.\n",
    "        # 해당 함수를 사용해 target bbox로 예측된 두 개의 bbox에 대한 IoU를 계산한다.\n",
    "        # prediction에서 첫번째 bbox 좌표\n",
    "        iou_b1 = intersection_over_union(predictions[..., (self.C+1):(self.C+5)], target[..., (self.C+1):(self.C+5)])\n",
    "        # prediction에서 두번째 bbox 좌표\n",
    "        iou_b2 = intersection_over_union(predictions[..., (self.C+6):(self.C+self.B * 5)], target[..., (self.C+1):(self.C+5)])\n",
    "        ious = torch.cat([iou_b1.unsqueeze(0), iou_b2.unsqueeze(0)], dim=0)\n",
    "        print('iou_b1', iou_b1)\n",
    "        print('iou_b2', iou_b2)\n",
    "        print('ious', ious)\n",
    "        \n",
    "        # ious에서 두 예측 중에서 IoU가 가장 높은 상자를 선택\n",
    "        # 해당 값은 변수 bestbox에 저장한다. 이때 \n",
    "        # bestbox는 어떤 box가 가장 좋은지에 대해 0, 1의 인덱스로 저장된다.\n",
    "        iou_maxes, bestbox = torch.max(ious, dim=0)\n",
    "        # exists_box : target의 마지막 차원에서 bbox 존재 여부 나타내는 값 저장.\n",
    "        exists_box = target[..., 4].unsqueeze(3)  # in paper this is Iobj_i\n",
    "\n",
    "        \n",
    "        # ======================== #\n",
    "        #   FOR BOX COORDINATES    #\n",
    "        # ======================== #\n",
    "\n",
    "        # object 없는 상자를 0으로 설정.\n",
    "        # 두 prediction 중 이전에 계산 된 IoU에서 가장 높은 예측 중 하나만 꺼낸다.\n",
    "        box_predictions = exists_box * (\n",
    "            (\n",
    "                bestbox * predictions[..., (self.C+6):(self.C+self.B * 5)]\n",
    "                + (1 - bestbox) * predictions[..., (self.C+1):(self.C+5)]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        box_targets = exists_box * target[..., (self.C+1):(self.C+5)]\n",
    "\n",
    "        # =====================================================================\n",
    "        # box predictions의 tensor가 어떻게 구성되어있는지 확인하고 index 수정.\n",
    "        \n",
    "        # Take sqrt of width, height of boxes to ensure that\n",
    "        box_predictions[..., 2:4] = torch.sign(box_predictions[..., 2:4]) * torch.sqrt(\n",
    "            torch.abs(box_predictions[..., B:C] + 1e-6)\n",
    "        )\n",
    "        box_targets[..., 2:4] = torch.sqrt(box_targets[..., 2:4])\n",
    "        \n",
    "        # IoU기준으로 선택된 bbox 사용해 pred_bbox와 실제 bbox 간의 좌표 손실 계산.\n",
    "        box_loss = self.mse(\n",
    "            torch.flatten(box_predictions, end_dim=-2),\n",
    "            torch.flatten(box_targets, end_dim=-2),\n",
    "        )\n",
    "\n",
    "        \n",
    "        # ==================== #\n",
    "        #   FOR OBJECT LOSS    #\n",
    "        # ==================== #\n",
    "\n",
    "        # pred_box : IoU가 가장 높은 bbox의 신뢰도 점수\n",
    "        pred_box = (\n",
    "            bestbox * predictions[..., (self.C+5):(self.C+6)] + (1 - bestbox) * predictions[..., (self.C):(self.C+1)]\n",
    "        )\n",
    "        print('prediction box : ', pred_box)\n",
    "        # IoU기준으로 선택된 bbox에 해당하는 신뢰도 점수 사용하여 계산.\n",
    "        object_loss = self.mse(\n",
    "            torch.flatten(exists_box * pred_box),\n",
    "            torch.flatten(exists_box * target[..., (self.C):(self.C+1)]), # --> ?\n",
    "        )\n",
    "\n",
    "        \n",
    "        # ======================= #\n",
    "        #   FOR NO OBJECT LOSS    #\n",
    "        # ======================= #\n",
    "\n",
    "        # max_no_obj = torch.max(predictions[..., 20:21], predictions[..., 25:26])\n",
    "        # no_object_loss = self.mse(\n",
    "        #    torch.flatten((1 - exists_box) * max_no_obj, start_dim=1),\n",
    "        #    torch.flatten((1 - exists_box) * target[..., 20:21], start_dim=1),\n",
    "        #)\n",
    "\n",
    "        # 비객체 손실 계산 : 객체가 없는 grid cell에 대한 손실 계산.\n",
    "        # -> 신뢰도 점수에 대한 loss이고, 모델이 객체가 없는 위치에 대한 신뢰도를 낮출 수 있게 도와준다.\n",
    "        no_object_loss = self.mse(\n",
    "            torch.flatten((1 - exists_box) * predictions[..., (self.C):(self.C+1)], start_dim=1),\n",
    "            torch.flatten((1 - exists_box) * target[..., 4:5], start_dim=1)  # --> ?\n",
    "        )\n",
    "        \n",
    "        no_object_loss += self.mse(\n",
    "            torch.flatten((1 - exists_box) * predictions[..., (self.C+5):(self.C+6)], start_dim=1),\n",
    "            torch.flatten((1 - exists_box) * target[..., 4:5], start_dim=1)  # --> ?\n",
    "        )\n",
    "        \n",
    "        # ================== #\n",
    "        #   FOR CLASS LOSS   #\n",
    "        # ================== #\n",
    "        # 클래스 손실 게산 : 예측된 클래스 확률과 실제 클래스 정보 사이의 loss를 계산한다.\n",
    "        class_loss = self.mse(\n",
    "            torch.flatten(exists_box * predictions[..., :self.C], end_dim=-2,),\n",
    "            torch.flatten(exists_box * target[..., :self.C], end_dim=-2,),\n",
    "        )\n",
    "        \n",
    "        # box_loss , object_loss , no_object_loss , class_loss를 전부 더하기.\n",
    "        loss = (\n",
    "            self.lambda_coord * box_loss  # first two rows in paper\n",
    "            + object_loss  # third row in paper\n",
    "            + self.lambda_noobj * no_object_loss  # forth row\n",
    "            + class_loss  # fifth row\n",
    "        )\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb7ce18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7fd77134",
   "metadata": {},
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c3686d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(train_loader, model, optimizer, loss_fn):\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    mean_loss = []\n",
    "\n",
    "    for batch_idx, (x, y) in enumerate(loop):\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        out = model(x)\n",
    "        \n",
    "        loss = loss_fn(out, y)\n",
    "        mean_loss.append(loss.item())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # update progress bar\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    print(f\"Mean loss was {sum(mean_loss)/len(mean_loss)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e7b8e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = VOCDataset(\n",
    "    train_csv,\n",
    "    transform=transform,\n",
    "    img_dir=img_dir,\n",
    "    label_dir=label_dir\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=0,\n",
    "    pin_memory=PIN_MEMORY,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b228f808",
   "metadata": {},
   "source": [
    "### train loader에 값이 제대로 있는지 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6aa35507",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "846747a4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 448, 448])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d322f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a561c02",
   "metadata": {},
   "source": [
    "# model 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "6b533c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Yolov1(split_size=7, num_boxes=2, num_classes=4).to(DEVICE)\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
    ")\n",
    "loss_fn = YoloLoss()\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    load_checkpoint(torch.load(LOAD_MODEL_FILE), model, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6e28b4",
   "metadata": {},
   "source": [
    "# 훈련 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "57632d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  1\n",
      "for문 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:11<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[16, 7, 7, 30]' is invalid for input of size 10976",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15980\\3437721696.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'epoch : '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     pred_boxes, target_boxes = get_bboxes(\n\u001b[0m\u001b[0;32m      5\u001b[0m         \u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     )\n",
      "\u001b[1;32mD:\\yolo\\50\\utils.ipynb\u001b[0m in \u001b[0;36mget_bboxes\u001b[1;34m(loader, model, iou_threshold, threshold, pred_format, box_format, device)\u001b[0m\n",
      "\u001b[1;32mD:\\yolo\\50\\utils.ipynb\u001b[0m in \u001b[0;36mcellboxes_to_boxes\u001b[1;34m(out, S)\u001b[0m\n",
      "\u001b[1;32mD:\\yolo\\50\\utils.ipynb\u001b[0m in \u001b[0;36mconvert_cellboxes\u001b[1;34m(predictions, S)\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: shape '[16, 7, 7, 30]' is invalid for input of size 10976"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1)):\n",
    "    print('epoch : ', epoch + 1)\n",
    "\n",
    "    pred_boxes, target_boxes = get_bboxes(\n",
    "        train_loader, model, iou_threshold=0.3, threshold=0.3\n",
    "    )\n",
    "    print('pred_boxes : ', pred_boxes)\n",
    "    print('target_boxes : ', target_boxes)\n",
    "\n",
    "    mean_avg_prec = mean_average_precision(\n",
    "        pred_boxes, target_boxes, iou_threshold=0.5, box_format=\"midpoint\"\n",
    "    )\n",
    "    print(f\"Train mAP: {mean_avg_prec}\")\n",
    "\n",
    "    train_fn(train_loader, model, optimizer, loss_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d0a89c1",
   "metadata": {},
   "source": [
    "### 에러내용 : RuntimeError: shape '[16, 7, 7, 30]' is invalid for input of size 10976\n",
    "<br>\n",
    "발생이유<br><br>\n",
    "input shape이 [16, 7, 7, 30]이어야 하는데, 내가 사용한 input size는 [16, 7, 7, 14]이다.<br>\n",
    "yolo architecture에서 마지막 부분은 7x7x30이기 때문에 이에 맞추기..<br><br>\n",
    "\n",
    "## B:5, C:5로 변경해서 하기!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37e4c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b4c492",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
